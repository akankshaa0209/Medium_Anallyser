{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03fc5a6b-c1fe-43ee-b114-26ab8ec06b5b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.21)\n",
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.10.0-cp310-cp310-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pypdf\n",
      "  Using cached pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting newspaper3k\n",
      "  Using cached newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.13.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.54)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.11.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (3.11.16)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (2.2.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from faiss-cpu) (23.2)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.7.0-cp310-cp310-win_amd64.whl.metadata (29 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.13.0)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
      "  Using cached cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (5.3.2)\n",
      "Collecting nltk>=3.2.1 (from newspaper3k)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
      "  Using cached feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
      "  Using cached tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "  Using cached feedfinder2-0.0.4-py3-none-any.whl\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "  Using cached jieba3k-0.35.1-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
      "  Using cached tinysegmenter-0.3-py3-none-any.whl\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
      "  Using cached sgmllib3k-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: filelock in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (8.1.8)\n",
      "Collecting joblib (from nltk>=3.2.1->newspaper3k)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
      "  Using cached requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\trak400\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Using cached faiss_cpu-1.10.0-cp310-cp310-win_amd64.whl (13.7 MB)\n",
      "Using cached sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Using cached pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Using cached newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "Using cached cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
      "Using cached feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
      "Using cached torch-2.7.0-cp310-cp310-win_amd64.whl (212.5 MB)\n",
      "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Using cached scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl (41.2 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, threadpoolctl, scipy, safetensors, pypdf, joblib, feedparser, faiss-cpu, cssselect, torch, scikit-learn, requests-file, nltk, feedfinder2, tldextract, transformers, newspaper3k, sentence-transformers\n",
      "Successfully installed cssselect-1.3.0 faiss-cpu-1.10.0 feedfinder2-0.0.4 feedparser-6.0.11 jieba3k-0.35.1 joblib-1.4.2 newspaper3k-0.2.8 nltk-3.9.1 pypdf-5.4.0 requests-file-2.1.0 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-4.1.0 sgmllib3k-1.0.0 threadpoolctl-3.6.0 tinysegmenter-0.3 tldextract-5.3.0 torch-2.7.0 transformers-4.51.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community faiss-cpu sentence-transformers pypdf newspaper3k beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91e4d5b-f299-4ba0-bfa6-1d16d82a1b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Edge user-agent string\n",
    "os.environ[\"USER_AGENT\"] = (\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "    \"Chrome/117.0.0.0 Safari/537.36 Edg/117.0.2045.31\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "563d190f-7869-4f17-86b7-b539ba46bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd44f67-6000-4bb6-81ce-d53130f4d8f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version\n",
      "---------------------------------------- --------------\n",
      "aiohappyeyeballs                         2.6.1\n",
      "aiohttp                                  3.11.16\n",
      "aiosignal                                1.3.2\n",
      "annotated-types                          0.7.0\n",
      "anyio                                    4.9.0\n",
      "argon2-cffi                              23.1.0\n",
      "argon2-cffi-bindings                     21.2.0\n",
      "arrow                                    1.3.0\n",
      "asgiref                                  3.8.1\n",
      "asttokens                                3.0.0\n",
      "async-lru                                2.0.5\n",
      "async-timeout                            4.0.3\n",
      "attrs                                    25.3.0\n",
      "babel                                    2.17.0\n",
      "backoff                                  2.2.1\n",
      "bcrypt                                   4.3.0\n",
      "beautifulsoup4                           4.13.3\n",
      "bleach                                   6.2.0\n",
      "build                                    1.2.2.post1\n",
      "cachetools                               5.5.2\n",
      "certifi                                  2025.1.31\n",
      "cffi                                     1.17.1\n",
      "charset-normalizer                       3.4.1\n",
      "chroma-hnswlib                           0.7.6\n",
      "chromadb                                 0.6.3\n",
      "click                                    8.1.8\n",
      "colorama                                 0.4.6\n",
      "coloredlogs                              15.0.1\n",
      "comm                                     0.2.2\n",
      "contourpy                                1.3.1\n",
      "cssselect                                1.3.0\n",
      "cycler                                   0.12.1\n",
      "dataclasses-json                         0.6.7\n",
      "debugpy                                  1.8.13\n",
      "decorator                                5.2.1\n",
      "defusedxml                               0.7.1\n",
      "Deprecated                               1.2.18\n",
      "distro                                   1.9.0\n",
      "duckduckgo_search                        8.0.1\n",
      "durationpy                               0.9\n",
      "exceptiongroup                           1.2.2\n",
      "executing                                2.2.0\n",
      "faiss-cpu                                1.10.0\n",
      "fastapi                                  0.115.12\n",
      "fastjsonschema                           2.21.1\n",
      "feedfinder2                              0.0.4\n",
      "feedparser                               6.0.11\n",
      "filelock                                 3.18.0\n",
      "flatbuffers                              25.2.10\n",
      "fonttools                                4.56.0\n",
      "fqdn                                     1.5.1\n",
      "frozenlist                               1.5.0\n",
      "fsspec                                   2025.3.2\n",
      "google-auth                              2.39.0\n",
      "googleapis-common-protos                 1.70.0\n",
      "greenlet                                 3.1.1\n",
      "grpcio                                   1.71.0\n",
      "h11                                      0.14.0\n",
      "httpcore                                 1.0.7\n",
      "httptools                                0.6.4\n",
      "httpx                                    0.28.1\n",
      "httpx-sse                                0.4.0\n",
      "huggingface-hub                          0.30.2\n",
      "humanfriendly                            10.0\n",
      "idna                                     3.10\n",
      "importlib_metadata                       8.6.1\n",
      "importlib_resources                      6.5.2\n",
      "ipykernel                                6.29.5\n",
      "ipython                                  8.34.0\n",
      "ipywidgets                               8.1.6\n",
      "isoduration                              20.11.0\n",
      "jedi                                     0.19.2\n",
      "jieba3k                                  0.35.1\n",
      "Jinja2                                   3.1.6\n",
      "jiter                                    0.9.0\n",
      "joblib                                   1.4.2\n",
      "json5                                    0.11.0\n",
      "jsonpatch                                1.33\n",
      "jsonpointer                              3.0.0\n",
      "jsonschema                               4.23.0\n",
      "jsonschema-specifications                2024.10.1\n",
      "jupyter_client                           8.6.3\n",
      "jupyter_core                             5.7.2\n",
      "jupyter-events                           0.12.0\n",
      "jupyter-lsp                              2.2.5\n",
      "jupyter_server                           2.15.0\n",
      "jupyter_server_terminals                 0.5.3\n",
      "jupyterlab                               4.3.6\n",
      "jupyterlab_pygments                      0.3.0\n",
      "jupyterlab_server                        2.27.3\n",
      "jupyterlab_widgets                       3.0.14\n",
      "kiwisolver                               1.4.8\n",
      "kubernetes                               32.0.1\n",
      "langchain                                0.3.23\n",
      "langchain-chroma                         0.2.3\n",
      "langchain-community                      0.3.21\n",
      "langchain-core                           0.3.54\n",
      "langchain-ollama                         0.3.2\n",
      "langchain-openai                         0.3.14\n",
      "langchain-text-splitters                 0.3.8\n",
      "langsmith                                0.1.147\n",
      "lxml                                     5.3.2\n",
      "markdown-it-py                           3.0.0\n",
      "MarkupSafe                               3.0.2\n",
      "marshmallow                              3.26.1\n",
      "matplotlib                               3.10.1\n",
      "matplotlib-inline                        0.1.7\n",
      "mdurl                                    0.1.2\n",
      "mistune                                  3.1.3\n",
      "mmh3                                     5.1.0\n",
      "monotonic                                1.6\n",
      "mpmath                                   1.3.0\n",
      "multidict                                6.4.3\n",
      "mypy-extensions                          1.0.0\n",
      "nbclient                                 0.10.2\n",
      "nbconvert                                7.16.6\n",
      "nbformat                                 5.10.4\n",
      "nest-asyncio                             1.6.0\n",
      "networkx                                 3.4.2\n",
      "newspaper3k                              0.2.8\n",
      "nltk                                     3.9.1\n",
      "notebook                                 7.3.3\n",
      "notebook_shim                            0.2.4\n",
      "numpy                                    2.2.4\n",
      "oauthlib                                 3.2.2\n",
      "ollama                                   0.4.7\n",
      "onnxruntime                              1.21.0\n",
      "openai                                   1.75.0\n",
      "opentelemetry-api                        1.32.1\n",
      "opentelemetry-exporter-otlp-proto-common 1.32.1\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.32.1\n",
      "opentelemetry-instrumentation            0.53b1\n",
      "opentelemetry-instrumentation-asgi       0.53b1\n",
      "opentelemetry-instrumentation-fastapi    0.53b1\n",
      "opentelemetry-proto                      1.32.1\n",
      "opentelemetry-sdk                        1.32.1\n",
      "opentelemetry-semantic-conventions       0.53b1\n",
      "opentelemetry-util-http                  0.53b1\n",
      "orjson                                   3.10.16\n",
      "overrides                                7.7.0\n",
      "packaging                                23.2\n",
      "pandocfilters                            1.5.1\n",
      "parso                                    0.8.4\n",
      "pillow                                   11.1.0\n",
      "pip                                      25.0.1\n",
      "platformdirs                             4.3.7\n",
      "posthog                                  3.25.0\n",
      "primp                                    0.15.0\n",
      "prometheus_client                        0.21.1\n",
      "prompt_toolkit                           3.0.50\n",
      "propcache                                0.3.1\n",
      "protobuf                                 5.29.4\n",
      "psutil                                   7.0.0\n",
      "pure_eval                                0.2.3\n",
      "pyasn1                                   0.6.1\n",
      "pyasn1_modules                           0.4.2\n",
      "pycparser                                2.22\n",
      "pydantic                                 2.11.1\n",
      "pydantic_core                            2.33.0\n",
      "pydantic-settings                        2.8.1\n",
      "Pygments                                 2.19.1\n",
      "pyparsing                                3.2.3\n",
      "pypdf                                    5.4.0\n",
      "PyPika                                   0.48.9\n",
      "pyproject_hooks                          1.2.0\n",
      "pyreadline3                              3.5.4\n",
      "python-dateutil                          2.9.0.post0\n",
      "python-dotenv                            1.1.0\n",
      "python-json-logger                       3.3.0\n",
      "pywin32                                  310\n",
      "pywinpty                                 2.0.15\n",
      "PyYAML                                   6.0.2\n",
      "pyzmq                                    26.3.0\n",
      "referencing                              0.36.2\n",
      "regex                                    2024.11.6\n",
      "requests                                 2.32.3\n",
      "requests-file                            2.1.0\n",
      "requests-oauthlib                        2.0.0\n",
      "requests-toolbelt                        1.0.0\n",
      "rfc3339-validator                        0.1.4\n",
      "rfc3986-validator                        0.1.1\n",
      "rich                                     14.0.0\n",
      "rpds-py                                  0.24.0\n",
      "rsa                                      4.9.1\n",
      "safetensors                              0.5.3\n",
      "scikit-learn                             1.6.1\n",
      "scipy                                    1.15.2\n",
      "Send2Trash                               1.8.3\n",
      "sentence-transformers                    4.1.0\n",
      "setuptools                               57.4.0\n",
      "sgmllib3k                                1.0.0\n",
      "shellingham                              1.5.4\n",
      "six                                      1.17.0\n",
      "sniffio                                  1.3.1\n",
      "soupsieve                                2.6\n",
      "SQLAlchemy                               2.0.40\n",
      "stack-data                               0.6.3\n",
      "starlette                                0.46.2\n",
      "sympy                                    1.13.3\n",
      "tenacity                                 8.5.0\n",
      "terminado                                0.18.1\n",
      "threadpoolctl                            3.6.0\n",
      "tiktoken                                 0.9.0\n",
      "tinycss2                                 1.4.0\n",
      "tinysegmenter                            0.3\n",
      "tldextract                               5.3.0\n",
      "tokenizers                               0.21.1\n",
      "tomli                                    2.2.1\n",
      "torch                                    2.7.0\n",
      "tornado                                  6.4.2\n",
      "tqdm                                     4.67.1\n",
      "traitlets                                5.14.3\n",
      "transformers                             4.51.3\n",
      "typer                                    0.15.2\n",
      "types-python-dateutil                    2.9.0.20241206\n",
      "typing_extensions                        4.13.0\n",
      "typing-inspect                           0.9.0\n",
      "typing-inspection                        0.4.0\n",
      "uri-template                             1.3.0\n",
      "urllib3                                  2.3.0\n",
      "uvicorn                                  0.34.1\n",
      "watchfiles                               1.0.5\n",
      "wcwidth                                  0.2.13\n",
      "webcolors                                24.11.1\n",
      "webencodings                             0.5.1\n",
      "websocket-client                         1.8.0\n",
      "websockets                               15.0.1\n",
      "widgetsnbextension                       4.0.14\n",
      "wikipedia                                1.4.0\n",
      "wrapt                                    1.17.2\n",
      "yarl                                     1.19.0\n",
      "zipp                                     3.21.0\n",
      "zstandard                                0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a48d6110-cb3b-415a-89f7-b3349b9812f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 1\n",
      "First document content: Understanding GenAI Models in depth | by vinay kumar | Techartifact-Technology learning | MediumOpen in appSign upSign inWriteSign upSign inTechartifact-Technology learning·An experience of the journey of development →architecture → transformation leadershipUnderstanding GenAI Models in depthvinay kumarFollow6 min read·Dec 5, 2024--ListenShareGenerative AI is a subset of artificial intelligence that focuses on creating models capable of generating new content, such as text, images, music, etc. I\n"
     ]
    }
   ],
   "source": [
    "#from langchain_community.document_loaders import WebBaseLoader\n",
    "# Step 1: Load Web Page Content\n",
    "\n",
    "# Set URL\n",
    "url = \"https://medium.com/techartifact-technology-learning/understanding-genai-in-depth-c820289ddeb3\"  # Replace with any URL \n",
    "\n",
    "# Load web page content\n",
    "loader = WebBaseLoader(url)\n",
    "documents = loader.load()\n",
    "\n",
    "# Check the loaded documents\n",
    "print(f\"Number of documents loaded: {len(documents)}\")\n",
    "print(f\"First document content: {documents[0].page_content[:500]}\")  # Print first 500 chars of the first document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81be6b22-8bcd-47bd-87e3-40f141852fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document metadata: {'source': 'https://medium.com/techartifact-technology-learning/understanding-genai-in-depth-c820289ddeb3', 'title': 'Understanding GenAI Models in depth | by vinay kumar | Techartifact-Technology learning | Medium', 'description': 'Generative AI is a subset of artificial intelligence that focuses on creating models capable of generating new content, such as text, images, music, etc. It refers to a class of artificial…', 'language': 'en'}\n",
      "Content preview: Understanding GenAI Models in depth | by vinay kumar | Techartifact-Technology learning | MediumOpen in appSign upSign inWriteSign upSign inTechartifact-Technology learning·An experience of the journey of development →architecture → transformation leadershipUnderstanding GenAI Models in depthvinay k\n"
     ]
    }
   ],
   "source": [
    "doc = documents[0]\n",
    "print(\"Document metadata:\", doc.metadata)\n",
    "print(\"Content preview:\", doc.page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d7a93be-49bc-4173-b949-58ef2b984f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 1\n",
      "First chunk content: Understanding GenAI Models in depth | by vinay kumar | Techartifact-Technology learning | MediumOpen in appSign upSign inWriteSign upSign inTechartifact-Technology learning·An experience of the journey of development →architecture → transformation leadershipUnderstanding GenAI Models in depthvinay kumarFollow6 min read·Dec 5, 2024--ListenShareGenerative AI is a subset of artificial intelligence that focuses on creating models capable of generating new content, such as text, images, music, etc. I\n"
     ]
    }
   ],
   "source": [
    "# from langchain_text_splitters import CharacterTextSplitter\n",
    "# Step 2: Split Text Into Chunks\n",
    "\n",
    "# Split documents into chunks of size 1000 with an overlap of 30 characters\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=30, separator=\"\\n\")\n",
    "docs = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "# Print out the number of chunks and the first chunk\n",
    "print(f\"Number of chunks: {len(docs)}\")\n",
    "print(f\"First chunk content: {docs[0].page_content[:500]}\")  # Print first 500 chars of the first chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2ffb3f0-6240-4eec-93d7-d8ecb282afaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First document embedding (vector): [-0.32377153635025024, 0.4590296149253845, 6.410435676574707, -2.1356775760650635, -0.22590740025043488, -0.08978856354951859, 0.1484341323375702, 1.1623140573501587, 1.0394806861877441, -1.6612409353256226]...\n"
     ]
    }
   ],
   "source": [
    "# from langchain_community.embeddings import OllamaEmbeddings\n",
    "# create embeddings\n",
    "\n",
    "# Use Ollama embeddings model\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")  # Use the model you prefer\n",
    "\n",
    "# Create embeddings for the documents\n",
    "embedded_docs = embeddings.embed_documents([doc.page_content for doc in docs])\n",
    "\n",
    "# Print the first embedding (a numerical vector)\n",
    "print(f\"First document embedding (vector): {embedded_docs[0][:10]}...\")  # Print first 10 values of the first embedding vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39876f80-1186-4831-92b0-55821a383620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved.\n"
     ]
    }
   ],
   "source": [
    "# from langchain_community.vectorstores import FAISS\n",
    "#  Step 4: Store Embeddings in FAISS Vector Store\n",
    "\n",
    "# Create a FAISS vector store from the embeddings\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# Save the vector store locally\n",
    "vectorstore.save_local(\"faiss_index_react\")\n",
    "\n",
    "# Check if FAISS index has been saved\n",
    "print(\"FAISS index saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2fac168-5de3-4660-8df0-ab2077e95013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index loaded.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Load FAISS Vector Store\n",
    "\n",
    "# Load the saved FAISS index\n",
    "new_vectorstore = FAISS.load_local(\"faiss_index_react\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Confirm it's loaded\n",
    "print(\"FAISS index loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd3dcf6d-e2f1-4b61-8935-8f576e6f474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer to 'What do you mean by transformer-based models?': Transformer-based models are a type of generative AI model that revolutionize language processing, enabling advanced tasks such as translation, summarization, and natural language understanding. They primarily use an attention mechanism to process input sequences, focusing on relevant parts of the input regardless of their position, and processes data in parallel, making it more efficient than traditional sequential models (e.g., RNNs).\n"
     ]
    }
   ],
   "source": [
    "# from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "# from langchain_community.llms import Ollama\n",
    "# Step 6: Set Up Retrieval and QA Chain\n",
    "\n",
    "# Set up the Ollama model\n",
    "llm = Ollama(model=\"llama3.2\")  # Use your preferred Ollama model\n",
    "\n",
    "# Create a Retrieval QA chain\n",
    "retrieval_qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=new_vectorstore.as_retriever())\n",
    "\n",
    "# Ask a sample question\n",
    "question = \"What do you mean by transformer-based models?\"\n",
    "response = retrieval_qa.run(question)\n",
    "\n",
    "# Print the response\n",
    "print(f\"Answer to '{question}': {response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
